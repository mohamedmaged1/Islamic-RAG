{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e46819cc",
   "metadata": {},
   "source": [
    "## Semantic Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b0fafc",
   "metadata": {},
   "source": [
    "* Here we will build a search engine over a PDF document. This will allow us to retrieve passages in the PDF that are similar to an input query.\n",
    "\n",
    "* Concepts\n",
    "    * Documents and document loaders\n",
    "    * Text splitters\n",
    "    * Embeddings\n",
    "    * Vector stores and retrievers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ce93d6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e06820b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install  pypdf arabic_reshaper bidi langgraph pdfplumber pytesseract pillow langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac9cd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "os.environ['LANGCHAIN_API_KEY'] = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab992c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(\"all_splits.pkl\", \"rb\") as f:\n",
    "#     all_splits = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05998fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Build your own system prompt in Arabic or adjusted tone\n",
    "custom_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",  \"أنت رجل فى غايه الذكاء مقدم لك بيانات لتستمد منها اجاباتك بناء على سؤال مقدم لك واعلم انه يوجد ايات قرءانية مكتوبه بطريقه خطأ لا تستمد منها \"),\n",
    "    (\"human\", \"استخدم السياق التالي للإجابة على السؤال:\\n\\n{context}\\n\\nالسؤال: {question}\\n\\nالإجابة:\")\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c23f9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "من خلال السياق المقدم، يمكننا استخلاص أحكام الوضوء كما يلي:\n",
      "\n",
      "1. **غسل الوجه**: يجب غسل الوجه بالماء باستخدام الكفين لنقل الماء إلى الوجه.\n",
      "\n",
      "2. **غسل اليدين**: يتم غسل اليدين إلى المرفقين، اليمنى أولاً ثم اليسرى. يستحب استخدام الغرفة (الكوب أو الإناء) عند غسل كل يد على حدة.\n",
      "\n",
      "3. **مسح الرأس**: يجب مسح الرأس مرة واحدة باليدين بعد غسل اليدين.\n",
      "\n",
      "4. **غسل الرجلين**: يجب غسل الرجلين إلى الكعبين ثلاث مرات لكل رجل، beginning باليمين ثم اليسار.\n",
      "\n",
      "5. **التتابع**: الترتيب المذكور في السنة النبوية هو تتابع معين: الوجه، اليدين، مسح الرأس، ثم غسل الرجلين.\n",
      "\n",
      "6. **النية**:虽说 لم يذكر صراحة في النص، إلا أن النية من أساسيات الوضوء في الفقه الإسلامي.\n",
      "\n",
      "7. **استخدام الماء الطاهر**: يجب استخدام الماء الطاهر للوضوء. وإذا لم يوجد ماء، يجوز التيمم بصعيد طيب (تراب نظيف).\n",
      "\n",
      "8. **عدد الغسلات**: يستحب غسل الأعضاء ثلاث مرات، إلا الرأس الذي يمسح مرة واحدة.\n",
      "\n",
      "9. **التسمية**: من المستحب أيضاً أن يقول المسلم \"بسم الله\" قبل البدء بالوضوء.\n",
      "\n",
      "هذه هي الأحكام المستخلصة من النصوص المقدمة والتي توضح كيفية وأهمية الوضوء الصحيح.\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.embeddings import DashScopeEmbeddings  # Changed this\n",
    "from langchain import hub\n",
    "import bs4\n",
    "\n",
    "# Configure API key\n",
    "dashscope_api_key = \"\"\n",
    "dashscope_base_url = \"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n",
    "\n",
    "embeddings = DashScopeEmbeddings(\n",
    "    dashscope_api_key=dashscope_api_key,\n",
    "    model=\"text-embedding-v1\"  # DashScope's embedding model\n",
    ")\n",
    "\n",
    "# Create vectorstore\n",
    "vector_store = Chroma(embedding_function=embeddings)\n",
    "_ = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "retriever = vector_store.as_retriever(   \n",
    "    search_type=\"similarity\",    # or \"mmr\", \"similarity_score_threshold\"\n",
    "    search_kwargs={\"k\": 1}       # how many results to retrieve\n",
    ")\n",
    "\n",
    "#### RETRIEVAL and GENERATION ####\n",
    "prompt = custom_prompt\n",
    "\n",
    "\n",
    "# Configure LLM for DashScope\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"qwen-plus\",  # or whatever model you have access to\n",
    "    openai_api_key=dashscope_api_key,\n",
    "    openai_api_base=dashscope_base_url,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "# Chain\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "# Question\n",
    "response = rag_chain.invoke(\"ما هى أحكام الوضوء ؟\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f848576e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "الحائض لا تصوم أثناء فترة الحيض، لأن الصيام ليس مستحقًا对她 خلال هذه الفترة. وبعد انتهاء الحيض، يُصبح عليها قضاء الأيام التي أفطرتها بسبب الحيض بعد أن تتطهر (بإتمام الغسل وما إلى ذلك)، ولكنها ليست ملزمة بصيام هذه الأيام في أوقات محددة طالما تقضيها قبل حلول نفس الشهر من العام المقبل.\n",
      "\n",
      "**الاستناد إلى النصوص المقدمة:**\n",
      "- الحديث الذي روي عن النبي ﷺ يوضح للمرأة المستحاضة أو الحائض كيف تتصرف بشأن الصلاة والطهارة، وهذا يمكن تعميمه أيضًا على الصيام بناءً على الأدلة الشرعية الأخرى.\n",
      "- قال النبي ﷺ: \"فإذا تطهرّن فاتوهن من حيث أمركم الله\". هذا يعني أنه بعد الطهر يجب استئناف العبادات المفروضة مثل الصلاة والصيام.\n",
      "\n",
      "وبالتالي، الإجابة هي: **تصوم الحائض بعد أن تنتهي من حيضها وتطهر، ثم تقوم بقضاء الأيام التي أفطرتها بسبب الحيض في أي وقت آخر قبل حلول رمضان القادم.**\n"
     ]
    }
   ],
   "source": [
    "text = \"متى تصوم الحائض ؟\"\n",
    "response = rag_chain.invoke(text)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf6044c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    }
   ],
   "source": [
    "from typing import Literal\n",
    "import bs4\n",
    "from langchain import hub\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langgraph.graph import START, StateGraph\n",
    "from typing_extensions import Annotated, List, TypedDict\n",
    "\n",
    "\n",
    "\n",
    "# Update metadata (illustration purposes)\n",
    "total_documents = len(all_splits)\n",
    "third = total_documents // 3\n",
    "\n",
    "for i, document in enumerate(all_splits):\n",
    "    if i < third:\n",
    "        document.metadata[\"section\"] = \"beginning\"\n",
    "    elif i < 2 * third:\n",
    "        document.metadata[\"section\"] = \"middle\"\n",
    "    else:\n",
    "        document.metadata[\"section\"] = \"end\"\n",
    "\n",
    "\n",
    "# Index chunks\n",
    "vector_store = InMemoryVectorStore(embeddings)\n",
    "_ = vector_store.add_documents(all_splits)\n",
    "\n",
    "\n",
    "# Define schema for search\n",
    "class Search(TypedDict):\n",
    "    \"\"\"Search query.\"\"\"\n",
    "\n",
    "    query: Annotated[str, ..., \"Search query to run.\"]\n",
    "    section: Annotated[\n",
    "        Literal[\"beginning\", \"middle\", \"end\"],\n",
    "        ...,\n",
    "        \"Section to query.\",\n",
    "    ]\n",
    "\n",
    "# Define prompt for question-answering\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"qwen-max\",  # or whatever model you have access to\n",
    "    openai_api_key=dashscope_api_key,\n",
    "    openai_api_base=dashscope_base_url,\n",
    "    temperature=0\n",
    ")\n",
    "\n",
    "# Define state for application\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    query: Search\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "def analyze_query(state: State):\n",
    "    structured_llm = llm.with_structured_output(Search)\n",
    "    query = structured_llm.invoke(state[\"question\"])\n",
    "    return {\"query\": query}\n",
    "\n",
    "\n",
    "def retrieve(state: State):\n",
    "    query = state[\"query\"]\n",
    "    retrieved_docs = vector_store.similarity_search(\n",
    "        query[\"query\"],\n",
    "        filter=lambda doc: doc.metadata.get(\"section\") == query[\"section\"],\n",
    "    )\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return \"answer\": response.content\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State).add_sequence([analyze_query, retrieve, generate])\n",
    "graph_builder.add_edge(START, \"analyze_query\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bf27ebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x00000126281E27D0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c85e321",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'code': 'invalid_parameter_error', 'param': None, 'message': \"<400> InternalError.Algo.InvalidParameter: 'messages' must contain the word 'json' in some form, to use 'response_format' of type 'json_object'.\", 'type': 'invalid_request_error'}, 'id': 'chatcmpl-81f60d76-90c4-9d5d-9949-969caf35b39d', 'request_id': '81f60d76-90c4-9d5d-9949-969caf35b39d'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m      2\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mالصلاة \u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m      3\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdates\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m      4\u001b[0m ):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m----------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Yalla\\anaconda3\\envs\\yalla\\lib\\site-packages\\langgraph\\pregel\\__init__.py:2527\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[0;32m   2525\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mmatch_cached_writes():\n\u001b[0;32m   2526\u001b[0m             loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 2527\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   2528\u001b[0m             [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mwrites],\n\u001b[0;32m   2529\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   2530\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   2531\u001b[0m             schedule_task\u001b[38;5;241m=\u001b[39mloop\u001b[38;5;241m.\u001b[39maccept_push,\n\u001b[0;32m   2532\u001b[0m         ):\n\u001b[0;32m   2533\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   2534\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[0;32m   2535\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Yalla\\anaconda3\\envs\\yalla\\lib\\site-packages\\langgraph\\pregel\\runner.py:157\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[0;32m    155\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 157\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m                \u001b[49m\u001b[43mreraise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\Yalla\\anaconda3\\envs\\yalla\\lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32mc:\\Users\\Yalla\\anaconda3\\envs\\yalla\\lib\\site-packages\\langgraph\\utils\\runnable.py:623\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m--> 623\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    625\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\Yalla\\anaconda3\\envs\\yalla\\lib\\site-packages\\langgraph\\utils\\runnable.py:377\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    375\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(ret)\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 377\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[5], line 62\u001b[0m, in \u001b[0;36manalyze_query\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21manalyze_query\u001b[39m(state: State):\n\u001b[0;32m     61\u001b[0m     structured_llm \u001b[38;5;241m=\u001b[39m llm\u001b[38;5;241m.\u001b[39mwith_structured_output(Search)\n\u001b[1;32m---> 62\u001b[0m     query \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_llm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: query}\n",
      "File \u001b[1;32mc:\\Users\\Yalla\\anaconda3\\envs\\yalla\\lib\\site-packages\\langchain_core\\runnables\\base.py:3032\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   3030\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[0;32m   3031\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 3032\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   3033\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3034\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\Yalla\\anaconda3\\envs\\yalla\\lib\\site-packages\\langchain_core\\runnables\\base.py:5416\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m   5409\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m   5410\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m   5411\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5414\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[0;32m   5415\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[1;32m-> 5416\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbound\u001b[38;5;241m.\u001b[39minvoke(\n\u001b[0;32m   5417\u001b[0m         \u001b[38;5;28minput\u001b[39m,\n\u001b[0;32m   5418\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_merge_configs(config),\n\u001b[0;32m   5419\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs},\n\u001b[0;32m   5420\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Yalla\\anaconda3\\envs\\yalla\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:370\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[1;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[0;32m    360\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    366\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[0;32m    367\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[0;32m    368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[0;32m    369\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mChatGeneration\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m--> 370\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate_prompt(\n\u001b[0;32m    371\u001b[0m             [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_input(\u001b[38;5;28minput\u001b[39m)],\n\u001b[0;32m    372\u001b[0m             stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    373\u001b[0m             callbacks\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    374\u001b[0m             tags\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtags\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    375\u001b[0m             metadata\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    376\u001b[0m             run_name\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_name\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    377\u001b[0m             run_id\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m    378\u001b[0m             \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    379\u001b[0m         )\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    380\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[1;32mc:\\Users\\Yalla\\anaconda3\\envs\\yalla\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:947\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[1;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    938\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[0;32m    939\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[0;32m    940\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    944\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[0;32m    945\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[0;32m    946\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[1;32m--> 947\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerate(prompt_messages, stop\u001b[38;5;241m=\u001b[39mstop, callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Yalla\\anaconda3\\envs\\yalla\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:766\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[0;32m    763\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[0;32m    764\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    765\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m--> 766\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate_with_cache(\n\u001b[0;32m    767\u001b[0m                 m,\n\u001b[0;32m    768\u001b[0m                 stop\u001b[38;5;241m=\u001b[39mstop,\n\u001b[0;32m    769\u001b[0m                 run_manager\u001b[38;5;241m=\u001b[39mrun_managers[i] \u001b[38;5;28;01mif\u001b[39;00m run_managers \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    770\u001b[0m                 \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m    771\u001b[0m             )\n\u001b[0;32m    772\u001b[0m         )\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    774\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[1;32mc:\\Users\\Yalla\\anaconda3\\envs\\yalla\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1012\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m   1010\u001b[0m     result \u001b[38;5;241m=\u001b[39m generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1012\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(\n\u001b[0;32m   1013\u001b[0m         messages, stop\u001b[38;5;241m=\u001b[39mstop, run_manager\u001b[38;5;241m=\u001b[39mrun_manager, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1014\u001b[0m     )\n\u001b[0;32m   1015\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1016\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Yalla\\anaconda3\\envs\\yalla\\lib\\site-packages\\langchain_openai\\chat_models\\base.py:937\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    935\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_client\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpayload)\n\u001b[0;32m    936\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m openai\u001b[38;5;241m.\u001b[39mBadRequestError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 937\u001b[0m         \u001b[43m_handle_openai_bad_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    938\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_responses_api(payload):\n\u001b[0;32m    939\u001b[0m     original_schema_obj \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Yalla\\anaconda3\\envs\\yalla\\lib\\site-packages\\langchain_openai\\chat_models\\base.py:935\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    933\u001b[0m payload\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    934\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 935\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_client\u001b[38;5;241m.\u001b[39mbeta\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mparse(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpayload)\n\u001b[0;32m    936\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m openai\u001b[38;5;241m.\u001b[39mBadRequestError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    937\u001b[0m     _handle_openai_bad_request(e)\n",
      "File \u001b[1;32mc:\\Users\\Yalla\\anaconda3\\envs\\yalla\\lib\\site-packages\\openai\\resources\\beta\\chat\\completions.py:158\u001b[0m, in \u001b[0;36mCompletions.parse\u001b[1;34m(self, messages, model, audio, response_format, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, seed, service_tier, stop, store, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mparser\u001b[39m(raw_completion: ChatCompletion) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ParsedChatCompletion[ResponseFormatT]:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _parse_chat_completion(\n\u001b[0;32m    153\u001b[0m         response_format\u001b[38;5;241m=\u001b[39mresponse_format,\n\u001b[0;32m    154\u001b[0m         chat_completion\u001b[38;5;241m=\u001b[39mraw_completion,\n\u001b[0;32m    155\u001b[0m         input_tools\u001b[38;5;241m=\u001b[39mtools,\n\u001b[0;32m    156\u001b[0m     )\n\u001b[1;32m--> 158\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maudio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_completion_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_completion_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    172\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    173\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodalities\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodalities\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    174\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    175\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    176\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprediction\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprediction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    177\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreasoning_effort\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mreasoning_effort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    179\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m_type_to_response_format\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    180\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    181\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mservice_tier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mservice_tier\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    182\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    183\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstore\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    185\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    186\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    187\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    188\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    189\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    190\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    191\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    192\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweb_search_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mweb_search_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    193\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpost_parser\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# we turn the `ChatCompletion` instance into a `ParsedChatCompletion`\u001b[39;49;00m\n\u001b[0;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# in the `parser` function above\u001b[39;49;00m\n\u001b[0;32m    205\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mType\u001b[49m\u001b[43m[\u001b[49m\u001b[43mParsedChatCompletion\u001b[49m\u001b[43m[\u001b[49m\u001b[43mResponseFormatT\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mChatCompletion\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Yalla\\anaconda3\\envs\\yalla\\lib\\site-packages\\openai\\_base_client.py:1239\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1226\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1227\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1235\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1236\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1237\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1238\u001b[0m     )\n\u001b[1;32m-> 1239\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\Yalla\\anaconda3\\envs\\yalla\\lib\\site-packages\\openai\\_base_client.py:1034\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1031\u001b[0m             err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1033\u001b[0m         log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1034\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not resolve response (should never happen)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'code': 'invalid_parameter_error', 'param': None, 'message': \"<400> InternalError.Algo.InvalidParameter: 'messages' must contain the word 'json' in some form, to use 'response_format' of type 'json_object'.\", 'type': 'invalid_request_error'}, 'id': 'chatcmpl-81f60d76-90c4-9d5d-9949-969caf35b39d', 'request_id': '81f60d76-90c4-9d5d-9949-969caf35b39d'}"
     ]
    }
   ],
   "source": [
    "for step in graph.stream(\n",
    "    {\"question\": \"الصلاة \"},\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    print(f\"{step}\\n\\n----------------\\n\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55bea497",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yalla\\AppData\\Local\\Temp\\ipykernel_6540\\676520925.py:53: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Received unsupported arguments {'system_message': 'You are an assistant that extracts search queries and tags based on user questions. Respond with a JSON object in the format: {\"query\": ..., \"section\": ...}.'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 108\u001b[0m\n\u001b[0;32m    105\u001b[0m graph \u001b[38;5;241m=\u001b[39m graph_builder\u001b[38;5;241m.\u001b[39mcompile()\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m# ✅ Run as a stream\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step \u001b[38;5;129;01min\u001b[39;00m graph\u001b[38;5;241m.\u001b[39mstream(\n\u001b[0;32m    109\u001b[0m     {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mما هي الصلاة؟ أجب بصيغة JSON.\u001b[39m\u001b[38;5;124m\"\u001b[39m},  \u001b[38;5;66;03m# Arabic question + JSON instruction!\u001b[39;00m\n\u001b[0;32m    110\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupdates\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    111\u001b[0m ):\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28mprint\u001b[39m(step)\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m30\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Yalla\\anaconda3\\envs\\yalla\\lib\\site-packages\\langgraph\\pregel\\__init__.py:2527\u001b[0m, in \u001b[0;36mPregel.stream\u001b[1;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[0m\n\u001b[0;32m   2525\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mmatch_cached_writes():\n\u001b[0;32m   2526\u001b[0m             loop\u001b[38;5;241m.\u001b[39moutput_writes(task\u001b[38;5;241m.\u001b[39mid, task\u001b[38;5;241m.\u001b[39mwrites, cached\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 2527\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[0;32m   2528\u001b[0m             [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m t\u001b[38;5;241m.\u001b[39mwrites],\n\u001b[0;32m   2529\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[0;32m   2530\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[0;32m   2531\u001b[0m             schedule_task\u001b[38;5;241m=\u001b[39mloop\u001b[38;5;241m.\u001b[39maccept_push,\n\u001b[0;32m   2532\u001b[0m         ):\n\u001b[0;32m   2533\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[0;32m   2534\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[0;32m   2535\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Yalla\\anaconda3\\envs\\yalla\\lib\\site-packages\\langgraph\\pregel\\runner.py:157\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[1;34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[0m\n\u001b[0;32m    155\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 157\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    167\u001b[0m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    168\u001b[0m \u001b[43m                \u001b[49m\u001b[43mreraise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    169\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    170\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    171\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    172\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    173\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\Yalla\\anaconda3\\envs\\yalla\\lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[1;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[0;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[1;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "File \u001b[1;32mc:\\Users\\Yalla\\anaconda3\\envs\\yalla\\lib\\site-packages\\langgraph\\utils\\runnable.py:623\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    621\u001b[0m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[0;32m    622\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[1;32m--> 623\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    625\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "File \u001b[1;32mc:\\Users\\Yalla\\anaconda3\\envs\\yalla\\lib\\site-packages\\langgraph\\utils\\runnable.py:377\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[1;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[0;32m    375\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(ret)\n\u001b[0;32m    376\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 377\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    378\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[0;32m    379\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "Cell \u001b[1;32mIn[10], line 72\u001b[0m, in \u001b[0;36manalyze_query\u001b[1;34m(state)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21manalyze_query\u001b[39m(state: State):\n\u001b[1;32m---> 72\u001b[0m     structured_llm \u001b[38;5;241m=\u001b[39m \u001b[43mllm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwith_structured_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43mSearch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43msystem_message\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mYou are an assistant that extracts search queries and tags based on user questions. Respond with a JSON object in the format: \u001b[39;49m\u001b[38;5;124;43m{\u001b[39;49m\u001b[38;5;130;43;01m\\\"\u001b[39;49;00m\u001b[38;5;124;43mquery\u001b[39;49m\u001b[38;5;130;43;01m\\\"\u001b[39;49;00m\u001b[38;5;124;43m: ..., \u001b[39;49m\u001b[38;5;130;43;01m\\\"\u001b[39;49;00m\u001b[38;5;124;43msection\u001b[39;49m\u001b[38;5;130;43;01m\\\"\u001b[39;49;00m\u001b[38;5;124;43m: ...}.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[0;32m     75\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     76\u001b[0m     query \u001b[38;5;241m=\u001b[39m structured_llm\u001b[38;5;241m.\u001b[39minvoke(state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: query}\n",
      "File \u001b[1;32mc:\\Users\\Yalla\\anaconda3\\envs\\yalla\\lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1440\u001b[0m, in \u001b[0;36mBaseChatModel.with_structured_output\u001b[1;34m(self, schema, include_raw, **kwargs)\u001b[0m\n\u001b[0;32m   1438\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[0;32m   1439\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived unsupported arguments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1440\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1442\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput_parsers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mopenai_tools\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m   1443\u001b[0m     JsonOutputKeyToolsParser,\n\u001b[0;32m   1444\u001b[0m     PydanticToolsParser,\n\u001b[0;32m   1445\u001b[0m )\n\u001b[0;32m   1447\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbind_tools \u001b[38;5;129;01mis\u001b[39;00m BaseChatModel\u001b[38;5;241m.\u001b[39mbind_tools:\n",
      "\u001b[1;31mValueError\u001b[0m: Received unsupported arguments {'system_message': 'You are an assistant that extracts search queries and tags based on user questions. Respond with a JSON object in the format: {\"query\": ..., \"section\": ...}.'}"
     ]
    }
   ],
   "source": [
    "from typing import Literal\n",
    "from typing_extensions import Annotated, List, TypedDict\n",
    "\n",
    "from langgraph.graph import START, StateGraph\n",
    "from langchain import hub\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.vectorstores import InMemoryVectorStore\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "# ✅ Load documents\n",
    "\n",
    "# ✅ Assign metadata tags (\"beginning\", \"middle\", \"end\")\n",
    "total_documents = len(all_splits)\n",
    "third = total_documents // 3\n",
    "\n",
    "for i, document in enumerate(all_splits):\n",
    "    if i < third:\n",
    "        document.metadata[\"section\"] = \"beginning\"\n",
    "    elif i < 2 * third:\n",
    "        document.metadata[\"section\"] = \"middle\"\n",
    "    else:\n",
    "        document.metadata[\"section\"] = \"end\"\n",
    "\n",
    "# ✅ Initialize vector store and add documents\n",
    "embeddings = DashScopeEmbeddings(\n",
    "    dashscope_api_key=dashscope_api_key,\n",
    "    model=\"text-embedding-v1\"  # DashScope's embedding model\n",
    ")\n",
    "\n",
    "# Create vectorstore\n",
    "vector_store = Chroma(embedding_function=embeddings)\n",
    "_ = vector_store.add_documents(documents=all_splits)\n",
    "\n",
    "\n",
    "# ✅ Define structured output schema for user query\n",
    "class Search(TypedDict):\n",
    "    \"\"\"Structured search schema.\"\"\"\n",
    "    query: Annotated[str, ..., \"Search query to run.\"]\n",
    "    section: Annotated[\n",
    "        Literal[\"beginning\", \"middle\", \"end\"],\n",
    "        ...,\n",
    "        \"Section of the text to query.\",\n",
    "    ]\n",
    "\n",
    "# ✅ Define conversational LLM with JSON support (Dashscope/Qwen)\n",
    "dashscope_api_key = \"sk-a3cde32217314715adb67f38f2d23723\"\n",
    "dashscope_base_url = \"https://dashscope.aliyuncs.com/compatible-mode/v1\"\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"qwen-max\",\n",
    "    openai_api_key=dashscope_api_key,\n",
    "    openai_api_base=dashscope_base_url,\n",
    "    temperature=0,\n",
    ")\n",
    "\n",
    "# ✅ Load a RAG prompt from LangChain hub\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "# ✅ Define application state type\n",
    "class State(TypedDict):\n",
    "    question: str\n",
    "    query: Search\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "# ✅ Step 1: Use LLM to extract structured query (must include JSON instruction)\n",
    "def analyze_query(state: State):\n",
    "    structured_llm = llm.with_structured_output(\n",
    "        Search,\n",
    "        system_message=\"You are an assistant that extracts search queries and tags based on user questions. Respond with a JSON object in the format: {\\\"query\\\": ..., \\\"section\\\": ...}.\"\n",
    "    )\n",
    "    query = structured_llm.invoke(state[\"question\"])\n",
    "    return {\"query\": query}\n",
    "\n",
    "# ✅ Step 2: Retrieve relevant documents based on query & section\n",
    "def retrieve(state: State):\n",
    "    query = state[\"query\"]\n",
    "    retrieved_docs = vector_store.similarity_search(\n",
    "        query[\"query\"],\n",
    "        filter=lambda doc: doc.metadata.get(\"section\") == query[\"section\"],\n",
    "    )\n",
    "    return {\"context\": retrieved_docs}\n",
    "\n",
    "# ✅ Step 3: Generate an answer based on retrieved docs & question\n",
    "def generate(state: State):\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "    messages = prompt.invoke({\"question\": state[\"question\"], \"context\": docs_content})\n",
    "    response = llm.invoke(messages)\n",
    "    return {\"answer\": response.content}\n",
    "\n",
    "# ✅ Build the LangGraph pipeline\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"analyze_query\", analyze_query)\n",
    "graph_builder.add_node(\"retrieve\", retrieve)\n",
    "graph_builder.add_node(\"generate\", generate)\n",
    "\n",
    "graph_builder.set_entry_point(\"analyze_query\")\n",
    "graph_builder.add_edge(\"analyze_query\", \"retrieve\")\n",
    "graph_builder.add_edge(\"retrieve\", \"generate\")\n",
    "\n",
    "graph = graph_builder.compile()\n",
    "\n",
    "# ✅ Run as a stream\n",
    "for step in graph.stream(\n",
    "    {\"question\": \"ما هي الصلاة؟ أجب بصيغة JSON.\"},  # Arabic question + JSON instruction!\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    print(step)\n",
    "    print(\"\\n\" + \"-\" * 30 + \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54431db4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
